{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iUr1roGjWuG"
      },
      "outputs": [],
      "source": [
        "# SEM CONVESAO PARA ALFABETO LATINO\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Nome do modelo de tradução inglês → russo\n",
        "modelo_nome = 'Helsinki-NLP/opus-mt-en-ru'\n",
        "\n",
        "# Carregar o tokenizer e o modelo\n",
        "tokenizer = MarianTokenizer.from_pretrained(modelo_nome)\n",
        "model = MarianMTModel.from_pretrained(modelo_nome)\n",
        "\n",
        "# Função de tradução\n",
        "def traduzir(texto_en):\n",
        "    # Tokenizar a frase em inglês\n",
        "    tokens = tokenizer([texto_en], return_tensors=\"pt\", padding=True)\n",
        "    # Gerar a tradução\n",
        "    traducao_ids = model.generate(**tokens)\n",
        "    # Decodificar a saída para string\n",
        "    traducao_ru = tokenizer.decode(traducao_ids[0], skip_special_tokens=True)\n",
        "    return traducao_ru\n",
        "\n",
        "# Teste simples\n",
        "while True:\n",
        "    frase = input(\"\\nDigite uma frase em inglês (ou 'sair'): \")\n",
        "    if frase.lower() == \"sair\":\n",
        "        break\n",
        "    resultado = traduzir(frase)\n",
        "    print(f\"Tradução em russo: {resultado}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "0c57322a1ab44b7c83d457d9a2d364f5",
            "e2029e9a9a724de1b46733e5a3be4484",
            "51e3382edc16404bb81d2fcce00841f6",
            "e2c381b73e984784b508460054ff1fbc",
            "33107123e80645cfa2329f42a684eb4f",
            "dac740d8f72e4d16966fde2db2eb540e",
            "abac215af45c477c98c268af88faeb5b",
            "281233b2b1384d4e9d3d7aeb5d7ee1ca"
          ]
        },
        "id": "_CXP9pqoqJVm",
        "outputId": "e56da15e-9565-4637-a78e-5b5e4f25fc4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c57322a1ab44b7c83d457d9a2d364f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2029e9a9a724de1b46733e5a3be4484",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "source.spm:   0%|          | 0.00/803k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51e3382edc16404bb81d2fcce00841f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "target.spm:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2c381b73e984784b508460054ff1fbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.60M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33107123e80645cfa2329f42a684eb4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dac740d8f72e4d16966fde2db2eb540e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/307M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abac215af45c477c98c268af88faeb5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/307M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "281233b2b1384d4e9d3d7aeb5d7ee1ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tradução em russo: Привет.\n",
            "Pronúncia: Privet.\n"
          ]
        }
      ],
      "source": [
        "#transformers: Biblioteca da Hugging Face usada para carregar o modelo de tradução (MarianMT).\n",
        "#translit (do pacote transliterate): Transforma texto russo (alfabeto cirílico) em caracteres latinos, facilitando a leitura da pronúncia\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from transliterate import translit\n",
        "\n",
        "#Esse é o nome do modelo da Hugging Face que traduz de inglês (en) para russo (ru), baseado no MarianMT\n",
        "# Modelo de tradução: inglês → russo\n",
        "modelo_nome = 'Helsinki-NLP/opus-mt-en-ru'\n",
        "\n",
        "# tokenizer: Transforma texto em \"tokens\", que o modelo consegue entender.\n",
        "# model: O modelo de tradução propriamente dito\n",
        "# Carregar tokenizer e modelo\n",
        "tokenizer = MarianTokenizer.from_pretrained(modelo_nome)\n",
        "model = MarianMTModel.from_pretrained(modelo_nome)\n",
        "\n",
        "# Função de tradução com pronúncia\n",
        "def traduzir(texto_en):\n",
        "    #Transforma o texto de entrada (em inglês) em tokens\n",
        "    # return_tensors=\"pt\" Retorna os tokens como tensores PyTorch.\n",
        "    tokens = tokenizer([texto_en], return_tensors=\"pt\", padding=True)\n",
        "    # O modelo processa os tokens e gera a tradução, como uma sequência de IDs de palavras\n",
        "    traducao_ids = model.generate(**tokens)\n",
        "    # Converte os IDs de volta para texto russo, removendo símbolos especiais (skip_special_tokens=True).\n",
        "    traducao_ru = tokenizer.decode(traducao_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Romanizar (transliterate) o russo para alfabeto latino\n",
        "    pronuncia = translit(traducao_ru, 'ru', reversed=True)\n",
        "\n",
        "    return traducao_ru, pronuncia\n",
        "\n",
        "# Teste no terminal\n",
        "while True:\n",
        "    frase = input(\"\\nDigite uma frase em inglês (ou 'sair'): \")\n",
        "    if frase.lower() == \"sair\":\n",
        "        break\n",
        "    resultado_ru, resultado_pron = traduzir(frase)\n",
        "    print(f\"Tradução em russo: {resultado_ru}\")\n",
        "    print(f\"Pronúncia: {resultado_pron}\")\n",
        "\n",
        "'''\n",
        "Basicamente esta biblioteca para traducao usa algo parecido com as fases de um compilador.\n",
        "Se quiser enterder um pouco mais o processo de compilacao em um compilador para ter uma ideia do processo de\n",
        "que este codigo e a biblioteca contida utiliza - https://www.geeksforgeeks.org/phases-of-a-compiler/.\n",
        "\n",
        "Sao contextos totalmente diferentes, porem a ideia central e a mesma.\n",
        "Em um compilador ele cria os tokens e traduz o seu codigo para linguam de maquina (0,1).\n",
        "Aqui ele cria tokens de cada palavra escrita por voce, e as traduz para linguagem natural NLP.\n",
        "https://huggingface.co/docs/transformers/tokenizer_summary\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}